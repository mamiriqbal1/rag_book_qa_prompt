{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interact with your book 📖❓🙋🏻‍♀️\n",
    "\n",
    "A simple demonstration of how you can implement retrieval augmented generation for a book.\n",
    "\n",
    "## How retrieval augmented generation works\n",
    "\n",
    "Following are the high level steps needed for the implementation for retrieval augmented generation.\n",
    "\n",
    "1. Extract text from source. If the source is unstructured, like PDF, the extraction can be a challenge.\n",
    "2. Index the extracted text, often as vector embeddings and store.\n",
    "3. Let the user ask questions related to the source.\n",
    "4. Perform a similarity search in the index and retrieve relevant text chunks.\n",
    "5. Insert these text chunks in the prompt along with the question.\n",
    "6. Request an LLM (e.g. chatgpt) to produce an answer *only* based on the context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "from langchain import PromptTemplate\n",
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pdf file of the O Level Computer Science text book using PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reader = PdfReader(\"books/Cambridge IGCSE and O Level Computer Science.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensure proper text extraction\n",
    "\n",
    "We need to ensure that only relevant text is extracted. Only the main body text is extracted.\n",
    "\n",
    "   - Following sections are excluded: \n",
    "      - table of content, \n",
    "      - index, \n",
    "      - sample questions at the end of each chapter, \n",
    "      - diagrams, \n",
    "      - tables, and other elements that were not part of the main text.   \n",
    "\n",
    "We achieved the exclusions using following two identifications\n",
    "\n",
    "1. The main body of text is always using a specific font type. We have filtered on that.\n",
    "2. We have identified page numbers of the main text of the chapters. Only these were extracted.\n",
    "3. Since the text is extracted page by page, some pages only had very few words. All such texts were discarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pages extracted: 263\n"
     ]
    }
   ],
   "source": [
    "included_pages_intervals = [[14, 52],\n",
    "                 [57, 82],\n",
    "                 [87, 155],\n",
    "                 [159, 188],\n",
    "                 [192, 225],\n",
    "                 [229, 264],\n",
    "                 [270, 306],\n",
    "                 [311, 348],\n",
    "                 [351, 365],\n",
    "                 [368, 393]]\n",
    "\n",
    "included_pages = []\n",
    "for interval in included_pages_intervals:\n",
    "    l = list(range(interval[0], interval[1]+1))\n",
    "    included_pages = included_pages + l\n",
    "\n",
    "\n",
    "def include_page(page_number):\n",
    "    one_based_page_number = page_number + 1\n",
    "    if one_based_page_number in included_pages:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "parts = []\n",
    "def visitor_body(text, cm, tm, fontDict, fontSize):\n",
    "    if fontDict is not None and '/ILTBBB+OfficinaSansStd' in fontDict['/BaseFont']:\n",
    "        parts.append(text)\n",
    "\n",
    "def extract_single_page(page):\n",
    "    page.extract_text(visitor_text=visitor_body),\n",
    "    text_body = \"\".join(parts)\n",
    "    text_body = text_body.replace('\\n', ' ')\n",
    "    return text_body\n",
    "\n",
    "\n",
    "def extract_pages(pdf_reader, source):\n",
    "    documents = []\n",
    "    \n",
    "    for page_number, page in enumerate(pdf_reader.pages):\n",
    "        if include_page(page_number):\n",
    "            doc = Document(\n",
    "                    page_content = extract_single_page(page),\n",
    "                    metadata={\"source\": source, \"page\": page_number},\n",
    "                    ) \n",
    "            if len(doc.page_content) > 100:\n",
    "                documents.append(doc)\n",
    "            else:\n",
    "                pass\n",
    "                # print('dropped page content: ' + doc.page_content)\n",
    "            global parts\n",
    "            parts =[]\n",
    "    return documents\n",
    "\n",
    "\n",
    "documents = extract_pages(reader, \"Cambridge IGCSE and O Level Computer Science.pdf\")\n",
    "\n",
    "print('pages extracted: ' + str(len(documents)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create chunks of size 800 with no overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have created 547 chunks from 263 pages\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 800,\n",
    "    chunk_overlap = 0\n",
    ")\n",
    "\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f'We have created {len(texts)} chunks from {len(documents)} pages')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create vector embeddings and save locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# ### download embeddings model\n",
    "# embeddings = HuggingFaceInstructEmbeddings(\n",
    "#     model_name = 'sentence-transformers/all-MiniLM-L6-v2',\n",
    "#     model_kwargs = {\"device\": \"cpu\"}\n",
    "# )\n",
    "\n",
    "# ### create embeddings and DB\n",
    "# vectordb = FAISS.from_documents(\n",
    "#     documents = texts, \n",
    "#     embedding = embeddings\n",
    "# )\n",
    "\n",
    "# ### persist vector database\n",
    "# vectordb.save_local(\"faiss_index_hp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load already saved vector embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "CPU times: user 250 ms, sys: 112 ms, total: 362 ms\n",
      "Wall time: 392 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "### download embeddings model\n",
    "embeddings = HuggingFaceInstructEmbeddings(\n",
    "    model_name = 'sentence-transformers/all-MiniLM-L6-v2',\n",
    "    model_kwargs = {\"device\": \"cpu\"}\n",
    ")\n",
    "\n",
    "### load vector DB embeddings\n",
    "vectordb : FAISS = FAISS.load_local(\n",
    "    \"faiss_index_hp\",\n",
    "    embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify that similarity search is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='(VIN). Check digits are used to identify errors in data entry  caused by mis-typing  or mis-scanning a barcode. They can usually detect the following types of error:  an incorrect digit entered, for example 5327 entered instead of 5307 transposition errors where two numbers have changed order, for example 5037  instead of 5307 omitted or extra digits, for example 537 instead of 5307 or 53107 instead  of 5307  phonetic errors, for example 13 (thirteen), instead of 30 (thirty). There are a number of different methods used to generate a check digit. Two common methods will be considered here:  ISBN 13 Modulo-11', metadata={'source': 'Cambridge IGCSE and O Level Computer Science.pdf', 'page': 71}),\n",
       " Document(page_content='A format check checks that the characters entered conform to a pre-defined  pattern, for example, in Chapter 9 the cub number must be in the form CUB9999. The pseudocode for this example will be given in the string handling section of Chapter 9. A check digit is the final digit included in a code; it is calculated from all the  other digits in the code. Check digits are used for barcodes, product codes, International Standard Book Numbers (ISBN) and Vehicle Identification Numbers (VIN). Check digits are used to identify errors in data entry caused by mis-typing or  mis-scanning a barcode. They can usually detect the following types of error:  an incorrect digit entered, for example, 5327 entered instead of 5307 transposition errors where two numbers have changed order for example 5037', metadata={'source': 'Cambridge IGCSE and O Level Computer Science.pdf', 'page': 290}),\n",
       " Document(page_content='computer if there are no differences, then the data was sent without error if the two sets of data are different, then an error occurred at some stage  during the data transmission. A check digit is the final digit included in a code; it is calculated from all the other digits in the code. Check digits are used for barcodes on products, such as International Standard Book Numbers (ISBN) and Vehicle Identification Numbers', metadata={'source': 'Cambridge IGCSE and O Level Computer Science.pdf', 'page': 70}),\n",
       " Document(page_content='instead of 5307 omitted or extra digits, for example, 537 instead of 5307 or 53107 instead of 5307  phonetic errors, for example, 13, thirteen, instead of 30, thirty.', metadata={'source': 'Cambridge IGCSE and O Level Computer Science.pdf', 'page': 290})]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### test if vector DB was loaded correctly\n",
    "results = vectordb.similarity_search('check digit')\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a prompt template requiring the LLM to generate an answer only based on the provided context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "Don't try to make up an answer, if you don't know just say that you don't know.\n",
    "Answer in the same language the question was asked.\n",
    "Use only the following pieces of context to answer the question at the end.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure that we will use top 3 results from similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory.vectorstore import VectorStoreRetriever\n",
    "\n",
    "retriever : VectorStoreRetriever = vectordb.as_retriever(search_kwargs = {\"k\": 5, \"search_type\" : \"similarity\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provide a question for which answer is required.\n",
    "- The final prompt including context will be copied to the clipboard.\n",
    "- You can paste the prompt on an LLM interface (e.g. chat.openai.com) and get your answer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Don't try to make up an answer, if you don't know just say that you don't know.\n",
      "Answer in the same language the question was asked.\n",
      "Use only the following pieces of context to answer the question at the end.\n",
      "\n",
      " Parity checking is one method used to check whether data has been changed or  corrupted following data transmission. This method is based on the number of 1-bits in a byte of data. The parity can be either called EVEN  (that is, an even number of 1-bits in the  byte) or ODD  (that is, an odd number of 1-bits in the byte). One of the bits in  the byte (usually the most significant bit or left-most bit) is reserved for a parity  bit. The parity bit is set according to whether the parity being used is even or  odd. For example, consider the byte: In this example, if the byte is using even parity, then the parity bit needs to be set to 0, since there is already an even number of 1-bits in the byte (four 1-bits). We thus get: In this example, if the byte is using odd parity, then the parity bit needs to be set to 1, since we need to have an odd number of 1-bits in the byte. We thus get: Before data is transferred, an agreement is made between sender and receiver regarding which type of parity is being used. Parity checks are therefore being used as a type of transmission protocol. other words, a parity check is done in both horizontal and vertical directions). As the following example shows, this method not only identifies that an error has occurred but also indicates where the error is. would be unable to make any sense of it. Data corruption is therefore a very real problem to a computer. Figure 2.13 could be the result of some data corruption following transmission which would make the text unintelligible to a computer. This is why error checking is such an important part of computer technology. The following section considers a number of ways that can be used to check for errors, so that you don’t end up with text as shown in Figure 2.13 above! There are a number of ways data can be checked for errors following  transmission:  parity checks checksum echo check. parity checking. Let us imagine we are transmitting the following byte, using even parity: Suppose more than one bit has been modified during data transmission. This  means the byte could have reached the destination as any of the following:\n",
      "\n",
      "Question: What is the weakness of parity check?\n",
      "Answer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "query = 'What is the weakness of parity check?'\n",
    "\n",
    "docs = retriever.get_relevant_documents(query)\n",
    "merged_context = ''\n",
    "for doc in docs:\n",
    "    merged_context = merged_context + ' ' + doc.page_content\n",
    "\n",
    "final_prompt = prompt_template.format(context=merged_context, question=query)\n",
    "print(final_prompt)\n",
    "\n",
    "import pyperclip\n",
    "pyperclip.copy(final_prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
